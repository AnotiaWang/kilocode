// Generated by continue
import { URL } from "node:url";

import GitHubCrawler from "./GitHubCrawler";
import { githubTestRepos } from "./github-repos";

describe("GitHubCrawler (real GitHub fetches)", () => {
  it("should crawl a known repository and retrieve some .md files", async () => {
    // Example known small repo, or pick one of your own
    const testUrl = new URL("https://github.com/octocat/Hello-World");
    const crawler = new GitHubCrawler(testUrl);
    // Gather pages
    const results: any[] = [];
    for await (const page of crawler.crawl()) {
      results.push(page);
    }
    // Basic checks
    expect(results).toBeInstanceOf(Array);
    // There's often a README.md; ensure some content was retrieved
    expect(results.length).toBeGreaterThan(0);
    expect(results[0]).toHaveProperty("path");
    expect(results[0]).toHaveProperty("content");
  });

  describe.each(githubTestRepos)("Crawling major repos", (repoUrl) => {
    it(`should fetch .md files from ${repoUrl}`, async () => {
      const testUrl = new URL(repoUrl);
      const crawler = new GitHubCrawler(testUrl);
      const results: any[] = [];
      await expect(async () => {
        for await (const page of crawler.crawl()) {
          results.push(page);
          if (results.length > 10) {
            console.log(`Reached 10 pages for ${testUrl}, moving on`);
            break;
          }
        }
      }).not.toThrow();
      // Quick checks
      results.forEach((page) => {
        expect(page).toHaveProperty("path");
        expect(page).toHaveProperty("url");
        expect(page).toHaveProperty("content");
      });
    });
  });
});
